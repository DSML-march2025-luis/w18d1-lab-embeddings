{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "This lab is designed to help you solidify your understanding of embeddings by applying them to tasks like semantic similarity, clustering, and building a semantic search system.\n",
    "\n",
    "### Tasks:\n",
    "- Task 1: Semantic Similarity Comparison\n",
    "- Task 2: Document Clustering\n",
    "- Task 3: Enhance the Semantic Search System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Semantic Similarity Comparison\n",
    "### Objective:\n",
    "Compare semantic similarity between pairs of sentences using cosine similarity and embeddings.\n",
    "\n",
    "### Steps:\n",
    "1. Load a pre-trained Sentence Transformer model.\n",
    "2. Encode the sentence pairs.\n",
    "3. Compute cosine similarity for each pair.\n",
    "\n",
    "### Dataset:\n",
    "- \"A dog is playing in the park.\" vs. \"A dog is running in a field.\"\n",
    "- \"I love pizza.\" vs. \"I enjoy ice cream.\"\n",
    "- \"What is AI?\" vs. \"How does a computer learn?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between:\n",
      "  'A dog is playing in the park.'\n",
      "  and\n",
      "  'A dog is running in a field.'\n",
      "  => 0.5220\n",
      "\n",
      "Similarity between:\n",
      "  'I love pizza.'\n",
      "  and\n",
      "  'I enjoy ice cream.'\n",
      "  => 0.5281\n",
      "\n",
      "Similarity between:\n",
      "  'What is AI?'\n",
      "  and\n",
      "  'How does a computer learn?'\n",
      "  => 0.3194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sentence pairs\n",
    "sentence_pairs = [\n",
    "    (\"A dog is playing in the park.\", \"A dog is running in a field.\"),\n",
    "    (\"I love pizza.\", \"I enjoy ice cream.\"),\n",
    "    (\"What is AI?\", \"How does a computer learn?\")\n",
    "]\n",
    "\n",
    "# Compute similarities\n",
    "def print_similarities(pairs):\n",
    "    for sent1, sent2 in pairs:\n",
    "        emb1 = model.encode(sent1, convert_to_tensor=True)\n",
    "        emb2 = model.encode(sent2, convert_to_tensor=True)\n",
    "        sim = cosine_similarity(emb1.cpu().numpy().reshape(1, -1), emb2.cpu().numpy().reshape(1, -1))[0][0]\n",
    "        print(f\"Similarity between:\\n  '{sent1}'\\n  and\\n  '{sent2}'\\n  => {sim:.4f}\\n\")\n",
    "\n",
    "print_similarities(sentence_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- Which sentence pairs are the most semantically similar? Why?\n",
    "    - The most similar pair is: \"I love pizza.\" + \"I enjoy ice cream.\"\n",
    "    - Both talk about liking food and use similar words, so their meaning is very close.\n",
    "\n",
    "- Can you think of cases where cosine similarity might fail to capture true semantic meaning?\n",
    "\n",
    "    - Sentences that seem alike but mean the opposite\n",
    "    - Sentences where the meaning depends on the situation and context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between:\n",
      "  'I like cats.'\n",
      "  and\n",
      "  'I don’t like cats.'\n",
      "  => 0.8046\n",
      "\n",
      "Similarity between:\n",
      "  'After a good presentation, she said, 'Great job!''\n",
      "  and\n",
      "  'After a terrible presentation, she just said with sarcasm, 'Great job!''\n",
      "  => 0.8206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence_pairs_2 = [\n",
    "    (\"I like cats.\", \"I don’t like cats.\"), # Sentences that seem alike but mean the opposite\n",
    "    (\"After a good presentation, she said, 'Great job!'\", \"After a terrible presentation, she just said with sarcasm, 'Great job!'\") # sentences where the meaning depends on the situation and context\n",
    "]\n",
    "\n",
    "\n",
    "print_similarities(sentence_pairs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Document Clustering\n",
    "### Objective:\n",
    "Cluster a set of text documents into similar groups based on their embeddings.\n",
    "\n",
    "### Steps:\n",
    "1. Encode the documents using Sentence Transformers.\n",
    "2. Use KMeans clustering to group the documents.\n",
    "3. Analyze the clusters for semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Documents to cluster\n",
    "documents = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How do I bake a chocolate cake?\",\n",
    "    \"What is the distance between Earth and Mars?\",\n",
    "    \"How do I change a flat tire on a car?\",\n",
    "    \"What is the best way to learn Python?\",\n",
    "    \"How do I fix a leaky faucet?\"\n",
    "]\n",
    "\n",
    "# Encode documents\n",
    "embeddings = model.encode(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KMeans clustering\n",
    "num_clusters = 4\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "kmeans.fit(embeddings)\n",
    "clusters = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: What is the capital of France?\n",
      "Cluster 3: How do I bake a chocolate cake?\n",
      "Cluster 1: What is the distance between Earth and Mars?\n",
      "Cluster 0: How do I change a flat tire on a car?\n",
      "Cluster 2: What is the best way to learn Python?\n",
      "Cluster 0: How do I fix a leaky faucet?\n"
     ]
    }
   ],
   "source": [
    "# Print cluster assignments\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Cluster {clusters[i]}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- How many clusters make the most sense? Why?\n",
    "    - 4 clusters provides good results\n",
    "\n",
    "- Examine the documents in each cluster. Are they semantically meaningful? Can you assign a semantic \"theme\" to each cluster?\n",
    "    - Yes, the seem to be semantically meaningful: DIY topics / Geography / Coding / Cooking\n",
    "\n",
    "- Try this exercise with a larger dataset of your choice\n",
    "    - Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How do I bake a chocolate cake?\",\n",
    "    \"What is the distance between Earth and Mars?\",\n",
    "    \"How do I change a flat tire?\",\n",
    "    \"What is the best way to learn Python?\",\n",
    "    \"How do I fix a leaky faucet?\",\n",
    "    \"What are the health benefits of meditation?\",\n",
    "    \"How to train a dog to sit?\",\n",
    "    \"Explain the theory of relativity\",\n",
    "    \"How can I improve my credit score?\",\n",
    "    \"What are symptoms of COVID-19?\",\n",
    "    \"How do airplanes fly?\",\n",
    "    \"Best exercises to lose belly fat?\",\n",
    "    \"What is the stock market?\",\n",
    "    \"How to make a website with HTML?\",\n",
    "    \"What causes climate change?\",\n",
    "    \"How to prepare for a job interview?\",\n",
    "    \"How does photosynthesis work?\",\n",
    "    \"What is quantum computing?\",\n",
    "    \"How to start investing in stocks?\",\n",
    "    \"How do I make homemade pasta?\",\n",
    "    \"What's a good recipe for apple pie?\",\n",
    "    \"How do I use a for loop in Python?\",\n",
    "    \"What is a closure in JavaScript?\",\n",
    "    \"What is the Higgs boson?\"\n",
    "]\n",
    "\n",
    "# Encode documents\n",
    "embeddings = model.encode(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: What is the capital of France?\n",
      "Cluster 1: How do I bake a chocolate cake?\n",
      "Cluster 0: What is the distance between Earth and Mars?\n",
      "Cluster 1: How do I change a flat tire?\n",
      "Cluster 3: What is the best way to learn Python?\n",
      "Cluster 2: How do I fix a leaky faucet?\n",
      "Cluster 1: What are the health benefits of meditation?\n",
      "Cluster 2: How to train a dog to sit?\n",
      "Cluster 0: Explain the theory of relativity\n",
      "Cluster 2: How can I improve my credit score?\n",
      "Cluster 2: What are symptoms of COVID-19?\n",
      "Cluster 0: How do airplanes fly?\n",
      "Cluster 1: Best exercises to lose belly fat?\n",
      "Cluster 0: What is the stock market?\n",
      "Cluster 2: How to make a website with HTML?\n",
      "Cluster 0: What causes climate change?\n",
      "Cluster 2: How to prepare for a job interview?\n",
      "Cluster 2: How does photosynthesis work?\n",
      "Cluster 0: What is quantum computing?\n",
      "Cluster 0: How to start investing in stocks?\n",
      "Cluster 2: How do I make homemade pasta?\n",
      "Cluster 1: What's a good recipe for apple pie?\n",
      "Cluster 3: How do I use a for loop in Python?\n",
      "Cluster 0: What is a closure in JavaScript?\n",
      "Cluster 0: What is the Higgs boson?\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 4 clusters\n",
    "#\n",
    "\n",
    "# Perform KMeans clustering\n",
    "num_clusters = 4\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "kmeans.fit(embeddings)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "# Print cluster assignments\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Cluster {clusters[i]}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Cluster 0: Science & General Knowledge\n",
    "- Cluster 1: Health, Fitness, and Food\n",
    "- Cluster 2: Self-Improvement & Practical How-Tos\n",
    "- Cluster 3: Python\n",
    "\n",
    "\n",
    "There's some sentences that don't get classified very well (eg \"How do I change a flat tire?\", or the sentences related to coding). Worth to explore with a higher number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: What is the capital of France?\n",
      "Cluster 1: How do I bake a chocolate cake?\n",
      "Cluster 0: What is the distance between Earth and Mars?\n",
      "Cluster 1: How do I change a flat tire?\n",
      "Cluster 3: What is the best way to learn Python?\n",
      "Cluster 2: How do I fix a leaky faucet?\n",
      "Cluster 1: What are the health benefits of meditation?\n",
      "Cluster 2: How to train a dog to sit?\n",
      "Cluster 0: Explain the theory of relativity\n",
      "Cluster 2: How can I improve my credit score?\n",
      "Cluster 2: What are symptoms of COVID-19?\n",
      "Cluster 0: How do airplanes fly?\n",
      "Cluster 1: Best exercises to lose belly fat?\n",
      "Cluster 0: What is the stock market?\n",
      "Cluster 2: How to make a website with HTML?\n",
      "Cluster 0: What causes climate change?\n",
      "Cluster 2: How to prepare for a job interview?\n",
      "Cluster 2: How does photosynthesis work?\n",
      "Cluster 0: What is quantum computing?\n",
      "Cluster 0: How to start investing in stocks?\n",
      "Cluster 2: How do I make homemade pasta?\n",
      "Cluster 1: What's a good recipe for apple pie?\n",
      "Cluster 3: How do I use a for loop in Python?\n",
      "Cluster 0: What is a closure in JavaScript?\n",
      "Cluster 0: What is the Higgs boson?\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 7 clusters\n",
    "#\n",
    "\n",
    "# Perform KMeans clustering\n",
    "num_clusters = 4\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "kmeans.fit(embeddings)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "# Print cluster assignments\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Cluster {clusters[i]}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, with a higher number of clusters it performs well, but it still fails with the sentences related to coding.\n",
    "\n",
    "For those cases, a domain-specific model can be helpful (e.g. code-search-net or microsoft/codebert-base). Another alternative is to try a different clustering algorithm (e.g. HDBSCAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "## Task 3: Semantic Search System\n",
    "### Objective:\n",
    "Create a semantic search engine:\n",
    "A user provides a query and you search the dataset for semantically relevant documents to return. Return the top 5 results.\n",
    "\n",
    "### Dataset:\n",
    "- Use the following set of documents:\n",
    "    - \"What is the capital of France?\"\n",
    "    - \"How do I bake a chocolate cake?\"\n",
    "    - \"What is the distance between Earth and Mars?\"\n",
    "    - \"How do I change a flat tire on a car?\"\n",
    "    - \"What is the best way to learn Python?\"\n",
    "    - \"How do I fix a leaky faucet?\"\n",
    "    - \"What are the best travel destinations in Europe?\"\n",
    "    - \"How do I set up a local server?\"\n",
    "    - \"What is quantum computing?\"\n",
    "    - \"How do I build a mobile app?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Documents dataset\n",
    "documents = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How do I bake a chocolate cake?\",\n",
    "    \"What is the distance between Earth and Mars?\",\n",
    "    \"How do I change a flat tire on a car?\",\n",
    "    \"What is the best way to learn Python?\",\n",
    "    \"How do I fix a leaky faucet?\",\n",
    "    \"What are the best travel destinations in Europe?\",\n",
    "    \"How do I set up a local server?\",\n",
    "    \"What is quantum computing?\",\n",
    "    \"How do I build a mobile app?\"\n",
    "]\n",
    "\n",
    "# Compute document embeddings\n",
    "doc_embeddings = model.encode(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the search function\n",
    "#This function should encode the user query and return the top N documents that most resemble it\n",
    "def semantic_search(query, documents, doc_embeddings, top_n=5):\n",
    "    query_embedding = model.encode([query])\n",
    "    similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "\n",
    "    print(\"\\nHere are the top documents matching your query:\")\n",
    "    for rank, i in enumerate(top_indices, start=1):\n",
    "        print(f\"{rank}. {documents[i]} ({similarities[i] * 100:.0f}% similarity)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here are the top documents matching your query:\n",
      "1. What are the best programming languages for web development? (56% similarity)\n",
      "2. What is quantum computing? (44% similarity)\n",
      "3. What is artificial intelligence? (42% similarity)\n",
      "4. What is machine learning? (35% similarity)\n",
      "5. What is the best way to learn Python? (32% similarity)\n"
     ]
    }
   ],
   "source": [
    "# Test the search function\n",
    "query = \"Explain programming languages.\"\n",
    "semantic_search(query, documents, doc_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- What are the top-ranked results for the given queries?\n",
    "    - see output\n",
    "- How can you improve the ranking explanation for users?\n",
    "    - displaying the % of similarity\n",
    "- Try this approach with a larger dataset\n",
    "    - let's go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: How can I start coding?\n",
      "\n",
      "Here are the top documents matching your query:\n",
      "1. What are the best programming languages for web development? (39% similarity)\n",
      "2. How do I start a vegetable garden? (38% similarity)\n",
      "3. What is the best way to learn Python? (34% similarity)\n",
      "4. How do I build a mobile app? (33% similarity)\n",
      "5. How do I learn to play the guitar? (29% similarity)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Query: Tips for healthy eating\n",
      "\n",
      "Here are the top documents matching your query:\n",
      "1. What are some healthy dinner recipes? (62% similarity)\n",
      "2. What are the benefits of meditation? (28% similarity)\n",
      "3. How do I improve my photography skills? (23% similarity)\n",
      "4. How do I prepare for a job interview? (22% similarity)\n",
      "5. How do I train for a marathon? (21% similarity)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Query: Explain how plants make food\n",
      "\n",
      "Here are the top documents matching your query:\n",
      "1. What is the process of photosynthesis? (49% similarity)\n",
      "2. How do I start a vegetable garden? (48% similarity)\n",
      "3. What are some healthy dinner recipes? (37% similarity)\n",
      "4. How do I build a mobile app? (27% similarity)\n",
      "5. What causes climate change? (24% similarity)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Query: Ways to relax and reduce stress\n",
      "\n",
      "Here are the top documents matching your query:\n",
      "1. What are the benefits of meditation? (50% similarity)\n",
      "2. How do I prepare for a job interview? (27% similarity)\n",
      "3. How do I improve my photography skills? (23% similarity)\n",
      "4. What are the symptoms of the flu? (20% similarity)\n",
      "5. How can I improve my public speaking skills? (20% similarity)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Query: What is the future of artificial intelligence?\n",
      "\n",
      "Here are the top documents matching your query:\n",
      "1. What is artificial intelligence? (69% similarity)\n",
      "2. What is machine learning? (43% similarity)\n",
      "3. What is quantum computing? (40% similarity)\n",
      "4. What is the history of the Internet? (27% similarity)\n",
      "5. What are the benefits of learning a second language? (24% similarity)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How do I bake a chocolate cake?\",\n",
    "    \"What is the distance between Earth and Mars?\",\n",
    "    \"How do I change a flat tire on a car?\",\n",
    "    \"What is the best way to learn Python?\",\n",
    "    \"How do I fix a leaky faucet?\",\n",
    "    \"What are the best travel destinations in Europe?\",\n",
    "    \"How do I set up a local server?\",\n",
    "    \"What is quantum computing?\",\n",
    "    \"How do I build a mobile app?\",\n",
    "    \"What are the symptoms of the flu?\",\n",
    "    \"How can I improve my public speaking skills?\",\n",
    "    \"What causes climate change?\",\n",
    "    \"How do I train for a marathon?\",\n",
    "    \"What is the fastest animal on Earth'?\",\n",
    "    \"How do I start a vegetable garden?\",\n",
    "    \"What are the benefits of meditation?\",\n",
    "    \"How do I create a budget plan?\",\n",
    "    \"What is machine learning?\",\n",
    "    \"How do I learn to play the guitar?\",\n",
    "    \"What are the best programming languages for web development?\",\n",
    "    \"What are the benefits of learning a second language?\",\n",
    "    \"What is the history of the Internet?\",\n",
    "    \"How do I prepare for a job interview?\",\n",
    "    \"What are some healthy dinner recipes?\",\n",
    "    \"How do I install Python on Windows?\",\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"How do I improve my photography skills?\",\n",
    "    \"What is the process of photosynthesis?\",\n",
    "    \"How do I set up a Wi-Fi network at home?\"\n",
    "]\n",
    "\n",
    "# Compute document embeddings\n",
    "doc_embeddings = model.encode(documents)\n",
    "\n",
    "\n",
    "\n",
    "queries = [\n",
    "    \"How can I start coding?\",\n",
    "    \"Tips for healthy eating\",\n",
    "    \"Explain how plants make food\",\n",
    "    \"Ways to relax and reduce stress\",\n",
    "    \"What is the future of artificial intelligence?\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\nQuery: {q}\")\n",
    "    semantic_search(q, documents, doc_embeddings)\n",
    "    print(f\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "- We get some decent results, specially for the top-1 result; however, in some cases, we also get some off-topic results (eg, \"start a vegetable garden\" ranks high for \"start coding\")\n",
    "\n",
    "Some ways to improve that:\n",
    "- Use a larger and more specific dataset (ie. using more documents and/or documents that are closely related to the expected queries)\n",
    "- Use larger models (e.g. `all-mpnet-base-v2`, `text-embedding-3-small`, `text-embedding-3-large`)\n",
    "- Filter by minimum threshold (eg. discard results under, say, 30% similarity to reduce noise)\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
